{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swipe Gesture Classification with LSTM\n",
    "\n",
    "Train an LSTM model to classify swipe gestures:\n",
    "- 0: Non-gesture\n",
    "- 1: Swipe Left\n",
    "- 2: Swipe Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths - UPDATE THESE AFTER RE-COLLECTING DATA WITH NEW FEATURES\n",
    "DATASET_PATHS = [\n",
    "    '../data/swipe_gesture_20260102_134712.csv',\n",
    "    '../data/swipe_gesture_20260103_032002.csv',\n",
    "    '../data/swipe_gesture_20260106_051821.csv',\n",
    "    '../data/swipe_gesture_20260110_162518.csv',\n",
    "    '../data/swipe_gesture_20260110_172552.csv',\n",
    "    '../data/swipe_gesture_20260115_092720.csv',\n",
    "    '../data/swipe_gesture_20260115_094459.csv',\n",
    "    '../data/swipe_gesture_20260115_150554.csv'\n",
    "]\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Model paths\n",
    "MODEL_SAVE_PATH = f'../models/{current_time}/swipe_gesture_classifier.keras'\n",
    "TFLITE_SAVE_PATH = f'../models/{current_time}/swipe_gesture_classifier.tflite'\n",
    "TFJS_SAVE_DIR = f'../models/{current_time}/swipe_gesture_tfjs'\n",
    "\n",
    "# Model parameters\n",
    "NUM_CLASSES = 3  # Non-gesture, Swipe Left, Swipe Right\n",
    "TIME_STEPS = 16  # History window size\n",
    "FEATURES_PER_STEP = 16  # [x, y, dx, dy, angle, dtheta] + 5 fingertips × 2 coords\n",
    "\n",
    "# Feature indices for reference:\n",
    "# 0-1: palm_x, palm_y (normalized by scale)\n",
    "# 2-3: dx, dy (velocity)\n",
    "# 4-5: angle, dtheta (orientation)\n",
    "# 6-7: thumb tip (x, y relative to palm)\n",
    "# 8-9: index tip\n",
    "# 10-11: middle tip\n",
    "# 12-13: ring tip\n",
    "# 14-15: pinky tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7345, 257)\n",
      "Expected: (samples, 257)\n",
      "\n",
      "Labels: (7345,)\n",
      "Features: (7345, 256)\n",
      "\n",
      "Class distribution:\n",
      "  Class 0: 2562 samples (34.9%)\n",
      "  Class 1: 2928 samples (39.9%)\n",
      "  Class 2: 1855 samples (25.3%)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "datasets = []\n",
    "for path in DATASET_PATHS:\n",
    "    data = np.atleast_2d(\n",
    "        np.loadtxt(path, delimiter=',', dtype='float32')\n",
    "    )\n",
    "    datasets.append(data)\n",
    "\n",
    "data = np.vstack(datasets)\n",
    "\n",
    "# Expected columns: 1 (label) + TIME_STEPS * FEATURES_PER_STEP\n",
    "expected_cols = 1 + TIME_STEPS * FEATURES_PER_STEP\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Expected: (samples, {expected_cols})\")\n",
    "\n",
    "if data.shape[1] != expected_cols:\n",
    "    print(f\"\\n⚠️  WARNING: Data has {data.shape[1]} columns, expected {expected_cols}\")\n",
    "    print(\"Make sure you collected data with the new 16-feature format!\")\n",
    "\n",
    "# Split into labels and features\n",
    "y = data[:, 0].astype(int)\n",
    "X = data[:, 1:]\n",
    "\n",
    "print(f\"\\nLabels: {y.shape}\")\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    count = np.sum(y == i)\n",
    "    print(f\"  Class {i}: {count} samples ({100*count/len(y):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X: (7345, 16, 16)\n",
      "\n",
      "Train: (5876, 16, 16), Test: (1469, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for LSTM: (samples, time_steps, features)\n",
    "X_reshaped = X.reshape(-1, TIME_STEPS, FEATURES_PER_STEP)\n",
    "print(f\"Reshaped X: {X_reshaped.shape}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "print(f\"\\nTrain: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikaizm/Documents/PROGRAMMING/ml-ai/hand-gesture-recognition-mediapipe/.venv/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_52          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_53          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,424</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_54          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_55          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_56          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_10     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_57          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_52          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │         \u001b[38;5;34m2,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_53          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,424\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_54          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m57,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_55          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_56          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_10     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_57          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,475</span> (404.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,475\u001b[0m (404.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,771</span> (401.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,771\u001b[0m (401.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimized Conv1D model for handling 16 features and 3 motion gestures\n",
    "# TFLite/TFJS compatible\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input normalization - using input_shape for TFJS compatibility\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(TIME_STEPS, FEATURES_PER_STEP)),\n",
    "    \n",
    "    # First Conv1D block - captures short-term temporal patterns\n",
    "    tf.keras.layers.Conv1D(48, kernel_size=3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Second Conv1D block - captures mid-range motion dynamics\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=5, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Third Conv1D block - captures longer temporal patterns\n",
    "    tf.keras.layers.Conv1D(128, kernel_size=7, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Fourth Conv1D block - refines high-level gesture patterns\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    # Dense layers for classification - reduced size\n",
    "    tf.keras.layers.Dense(32, activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     # Input normalization\n",
    "#     tf.keras.layers.BatchNormalization(input_shape=(TIME_STEPS, FEATURES_PER_STEP)),\n",
    "    \n",
    "#     # Block 1: Short-term patterns (local movements)\n",
    "#     tf.keras.layers.Conv1D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "#     # Block 2: Mid-range patterns (swipe trajectory)\n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=5, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "#     # Block 3: Long-range patterns (full gesture)\n",
    "#     tf.keras.layers.Conv1D(96, kernel_size=7, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "#     # Classification head\n",
    "#     tf.keras.layers.Dense(24, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     # Input normalization\n",
    "#     tf.keras.layers.BatchNormalization(input_shape=(TIME_STEPS, FEATURES_PER_STEP)),\n",
    "    \n",
    "#     # Block 1: Multi-scale short-term patterns (parallel kernels effect via stacking)\n",
    "#     tf.keras.layers.Conv1D(48, kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv1D(48, kernel_size=3, padding='same', activation='relu'),  # Stacked = effective kernel 5\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "#     # Block 2: Mid-range patterns with dilation (captures wider context)\n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=3, dilation_rate=2, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=3, dilation_rate=2, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "#     # Block 3: Long-range patterns (full gesture arc)\n",
    "#     tf.keras.layers.Conv1D(96, kernel_size=5, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv1D(96, kernel_size=5, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "#     # Block 4: High-level feature refinement\n",
    "#     tf.keras.layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "#     # Dual pooling for richer representation\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "#     # Deeper classification head\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH, \n",
    "        save_best_only=True, \n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=30, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, \n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m348/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.9622\n",
      "Epoch 1: val_accuracy improved from None to 0.93941, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 1: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.7777 - val_accuracy: 0.9394 - val_loss: 0.4543 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.6149\n",
      "Epoch 2: val_accuracy improved from 0.93941 to 0.95099, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 2: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.5740 - val_accuracy: 0.9510 - val_loss: 0.3977 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.5275\n",
      "Epoch 3: val_accuracy improved from 0.95099 to 0.96256, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 3: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.5054 - val_accuracy: 0.9626 - val_loss: 0.3506 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.4687\n",
      "Epoch 4: val_accuracy improved from 0.96256 to 0.97073, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 4: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.4475 - val_accuracy: 0.9707 - val_loss: 0.3009 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.4276\n",
      "Epoch 5: val_accuracy improved from 0.97073 to 0.97141, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 5: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9299 - loss: 0.4164 - val_accuracy: 0.9714 - val_loss: 0.2767 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.3918\n",
      "Epoch 6: val_accuracy did not improve from 0.97141\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.3797 - val_accuracy: 0.9666 - val_loss: 0.2664 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.3646\n",
      "Epoch 7: val_accuracy improved from 0.97141 to 0.97345, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 7: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.3576 - val_accuracy: 0.9735 - val_loss: 0.2410 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.3437\n",
      "Epoch 8: val_accuracy did not improve from 0.97345\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.3298 - val_accuracy: 0.9735 - val_loss: 0.2211 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.3263\n",
      "Epoch 9: val_accuracy improved from 0.97345 to 0.97685, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 9: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.3095 - val_accuracy: 0.9769 - val_loss: 0.2023 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.2979\n",
      "Epoch 10: val_accuracy did not improve from 0.97685\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.2968 - val_accuracy: 0.9748 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.2934\n",
      "Epoch 11: val_accuracy did not improve from 0.97685\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.2877 - val_accuracy: 0.9735 - val_loss: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.2763\n",
      "Epoch 12: val_accuracy improved from 0.97685 to 0.97958, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 12: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.2732 - val_accuracy: 0.9796 - val_loss: 0.1781 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.2701\n",
      "Epoch 13: val_accuracy did not improve from 0.97958\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9471 - loss: 0.2734 - val_accuracy: 0.9782 - val_loss: 0.1816 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.2681\n",
      "Epoch 14: val_accuracy improved from 0.97958 to 0.98026, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 14: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.2630 - val_accuracy: 0.9803 - val_loss: 0.1786 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.2677\n",
      "Epoch 15: val_accuracy did not improve from 0.98026\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.2639 - val_accuracy: 0.9796 - val_loss: 0.1764 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.2627\n",
      "Epoch 16: val_accuracy improved from 0.98026 to 0.98298, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 16: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.2564 - val_accuracy: 0.9830 - val_loss: 0.1640 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.2427\n",
      "Epoch 17: val_accuracy improved from 0.98298 to 0.98502, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 17: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9571 - loss: 0.2430 - val_accuracy: 0.9850 - val_loss: 0.1565 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.2602\n",
      "Epoch 18: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.2670 - val_accuracy: 0.9769 - val_loss: 0.1836 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.2550\n",
      "Epoch 19: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.2487 - val_accuracy: 0.9816 - val_loss: 0.1620 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.2466\n",
      "Epoch 20: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.2400 - val_accuracy: 0.9816 - val_loss: 0.1647 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.2414\n",
      "Epoch 21: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.2355 - val_accuracy: 0.9789 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.2569\n",
      "Epoch 22: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.2536 - val_accuracy: 0.9782 - val_loss: 0.1750 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.2459\n",
      "Epoch 23: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9588 - loss: 0.2364 - val_accuracy: 0.9830 - val_loss: 0.1601 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.2361\n",
      "Epoch 24: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.2341 - val_accuracy: 0.9843 - val_loss: 0.1616 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.2534\n",
      "Epoch 25: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.2279 - val_accuracy: 0.9809 - val_loss: 0.1586 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.2445\n",
      "Epoch 26: val_accuracy did not improve from 0.98502\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.2414 - val_accuracy: 0.9789 - val_loss: 0.1748 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.2271\n",
      "Epoch 27: val_accuracy did not improve from 0.98502\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.2241 - val_accuracy: 0.9789 - val_loss: 0.1780 - learning_rate: 0.0010\n",
      "Epoch 28/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.2260\n",
      "Epoch 28: val_accuracy improved from 0.98502 to 0.98911, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 28: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.2010 - val_accuracy: 0.9891 - val_loss: 0.1368 - learning_rate: 5.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.1914\n",
      "Epoch 29: val_accuracy improved from 0.98911 to 0.99115, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 29: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.1781 - val_accuracy: 0.9912 - val_loss: 0.1297 - learning_rate: 5.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.1797\n",
      "Epoch 30: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.1763 - val_accuracy: 0.9884 - val_loss: 0.1281 - learning_rate: 5.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.1766\n",
      "Epoch 31: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.1694 - val_accuracy: 0.9850 - val_loss: 0.1345 - learning_rate: 5.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.1664\n",
      "Epoch 32: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.1579 - val_accuracy: 0.9871 - val_loss: 0.1178 - learning_rate: 5.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.1671\n",
      "Epoch 33: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.1601 - val_accuracy: 0.9898 - val_loss: 0.1168 - learning_rate: 5.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.1587\n",
      "Epoch 34: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9780 - loss: 0.1560 - val_accuracy: 0.9843 - val_loss: 0.1192 - learning_rate: 5.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.1736\n",
      "Epoch 35: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.1577 - val_accuracy: 0.9877 - val_loss: 0.1155 - learning_rate: 5.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.1546\n",
      "Epoch 36: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.1546 - val_accuracy: 0.9884 - val_loss: 0.1196 - learning_rate: 5.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.1555\n",
      "Epoch 37: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.1456 - val_accuracy: 0.9905 - val_loss: 0.1094 - learning_rate: 5.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.1529\n",
      "Epoch 38: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.1517 - val_accuracy: 0.9898 - val_loss: 0.1149 - learning_rate: 5.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.1616\n",
      "Epoch 39: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.1484 - val_accuracy: 0.9905 - val_loss: 0.1094 - learning_rate: 5.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.1446\n",
      "Epoch 40: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.1425 - val_accuracy: 0.9850 - val_loss: 0.1345 - learning_rate: 5.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.1539\n",
      "Epoch 41: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1441 - val_accuracy: 0.9891 - val_loss: 0.1121 - learning_rate: 5.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.1497\n",
      "Epoch 42: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.1403 - val_accuracy: 0.9898 - val_loss: 0.1049 - learning_rate: 5.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.1458\n",
      "Epoch 43: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.1424 - val_accuracy: 0.9898 - val_loss: 0.1096 - learning_rate: 5.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.1435\n",
      "Epoch 44: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1364 - val_accuracy: 0.9898 - val_loss: 0.1036 - learning_rate: 5.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.1486\n",
      "Epoch 45: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1489 - val_accuracy: 0.9905 - val_loss: 0.1069 - learning_rate: 5.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.1506\n",
      "Epoch 46: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.1445 - val_accuracy: 0.9864 - val_loss: 0.1190 - learning_rate: 5.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.1649\n",
      "Epoch 47: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.1580 - val_accuracy: 0.9864 - val_loss: 0.1194 - learning_rate: 5.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.1394\n",
      "Epoch 48: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1370 - val_accuracy: 0.9898 - val_loss: 0.1135 - learning_rate: 5.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.1325\n",
      "Epoch 49: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.1293 - val_accuracy: 0.9877 - val_loss: 0.1119 - learning_rate: 5.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.1425\n",
      "Epoch 50: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1334 - val_accuracy: 0.9905 - val_loss: 0.0967 - learning_rate: 5.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.1369\n",
      "Epoch 51: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.1310 - val_accuracy: 0.9891 - val_loss: 0.1098 - learning_rate: 5.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.1441\n",
      "Epoch 52: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.1324 - val_accuracy: 0.9912 - val_loss: 0.1040 - learning_rate: 5.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.1314\n",
      "Epoch 53: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1296 - val_accuracy: 0.9912 - val_loss: 0.1061 - learning_rate: 5.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.1409\n",
      "Epoch 54: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.1382 - val_accuracy: 0.9877 - val_loss: 0.1129 - learning_rate: 5.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.1443\n",
      "Epoch 55: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.1390 - val_accuracy: 0.9877 - val_loss: 0.1036 - learning_rate: 5.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.1340\n",
      "Epoch 56: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.1303 - val_accuracy: 0.9871 - val_loss: 0.1073 - learning_rate: 5.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.1301\n",
      "Epoch 57: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.1245 - val_accuracy: 0.9912 - val_loss: 0.1000 - learning_rate: 5.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.1382\n",
      "Epoch 58: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.1381 - val_accuracy: 0.9898 - val_loss: 0.1078 - learning_rate: 5.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.1224\n",
      "Epoch 59: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.1226 - val_accuracy: 0.9905 - val_loss: 0.0990 - learning_rate: 5.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.1166\n",
      "Epoch 60: val_accuracy did not improve from 0.99115\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.1172 - val_accuracy: 0.9891 - val_loss: 0.0999 - learning_rate: 5.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.1153\n",
      "Epoch 61: val_accuracy did not improve from 0.99115\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.1062 - val_accuracy: 0.9912 - val_loss: 0.0929 - learning_rate: 2.5000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.1109\n",
      "Epoch 62: val_accuracy improved from 0.99115 to 0.99183, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 62: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.1063 - val_accuracy: 0.9918 - val_loss: 0.0921 - learning_rate: 2.5000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0913\n",
      "Epoch 63: val_accuracy did not improve from 0.99183\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0903 - val_accuracy: 0.9912 - val_loss: 0.0893 - learning_rate: 2.5000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0942\n",
      "Epoch 64: val_accuracy did not improve from 0.99183\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0898 - val_accuracy: 0.9891 - val_loss: 0.0902 - learning_rate: 2.5000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.1024\n",
      "Epoch 65: val_accuracy improved from 0.99183 to 0.99319, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 65: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0969 - val_accuracy: 0.9932 - val_loss: 0.0823 - learning_rate: 2.5000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0968\n",
      "Epoch 66: val_accuracy did not improve from 0.99319\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0881 - val_accuracy: 0.9925 - val_loss: 0.0841 - learning_rate: 2.5000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0878\n",
      "Epoch 67: val_accuracy improved from 0.99319 to 0.99455, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 67: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0865 - val_accuracy: 0.9946 - val_loss: 0.0786 - learning_rate: 2.5000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0968\n",
      "Epoch 68: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0971 - val_accuracy: 0.9932 - val_loss: 0.0764 - learning_rate: 2.5000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0965\n",
      "Epoch 69: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0919 - val_accuracy: 0.9925 - val_loss: 0.0838 - learning_rate: 2.5000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0774\n",
      "Epoch 70: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0777 - val_accuracy: 0.9925 - val_loss: 0.0837 - learning_rate: 2.5000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0881\n",
      "Epoch 71: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0923 - val_accuracy: 0.9932 - val_loss: 0.0852 - learning_rate: 2.5000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0838\n",
      "Epoch 72: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0858 - val_accuracy: 0.9912 - val_loss: 0.0845 - learning_rate: 2.5000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0887\n",
      "Epoch 73: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0855 - val_accuracy: 0.9925 - val_loss: 0.0804 - learning_rate: 2.5000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0879\n",
      "Epoch 74: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0829 - val_accuracy: 0.9918 - val_loss: 0.0807 - learning_rate: 2.5000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0934\n",
      "Epoch 75: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0957 - val_accuracy: 0.9912 - val_loss: 0.0853 - learning_rate: 2.5000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0785\n",
      "Epoch 76: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0822 - val_accuracy: 0.9898 - val_loss: 0.0899 - learning_rate: 2.5000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0850\n",
      "Epoch 77: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0822 - val_accuracy: 0.9898 - val_loss: 0.0849 - learning_rate: 2.5000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0771\n",
      "Epoch 78: val_accuracy did not improve from 0.99455\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0781 - val_accuracy: 0.9912 - val_loss: 0.0812 - learning_rate: 2.5000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0770\n",
      "Epoch 79: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0688 - val_accuracy: 0.9925 - val_loss: 0.0756 - learning_rate: 1.2500e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0705\n",
      "Epoch 80: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0719 - val_accuracy: 0.9932 - val_loss: 0.0765 - learning_rate: 1.2500e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0693\n",
      "Epoch 81: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0684 - val_accuracy: 0.9925 - val_loss: 0.0765 - learning_rate: 1.2500e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0719\n",
      "Epoch 82: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0682 - val_accuracy: 0.9939 - val_loss: 0.0758 - learning_rate: 1.2500e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0646\n",
      "Epoch 83: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0634 - val_accuracy: 0.9918 - val_loss: 0.0737 - learning_rate: 1.2500e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0634\n",
      "Epoch 84: val_accuracy did not improve from 0.99455\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0611 - val_accuracy: 0.9939 - val_loss: 0.0713 - learning_rate: 1.2500e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0688\n",
      "Epoch 85: val_accuracy improved from 0.99455 to 0.99523, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 85: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0634 - val_accuracy: 0.9952 - val_loss: 0.0721 - learning_rate: 1.2500e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0613\n",
      "Epoch 86: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0596 - val_accuracy: 0.9925 - val_loss: 0.0819 - learning_rate: 1.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0633\n",
      "Epoch 87: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0643 - val_accuracy: 0.9925 - val_loss: 0.0743 - learning_rate: 1.2500e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0615\n",
      "Epoch 88: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0632 - val_accuracy: 0.9939 - val_loss: 0.0688 - learning_rate: 1.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0590\n",
      "Epoch 89: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0581 - val_accuracy: 0.9932 - val_loss: 0.0731 - learning_rate: 1.2500e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0634\n",
      "Epoch 90: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0639 - val_accuracy: 0.9925 - val_loss: 0.0743 - learning_rate: 1.2500e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0616\n",
      "Epoch 91: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0597 - val_accuracy: 0.9946 - val_loss: 0.0695 - learning_rate: 1.2500e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0595\n",
      "Epoch 92: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0574 - val_accuracy: 0.9925 - val_loss: 0.0722 - learning_rate: 1.2500e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0559\n",
      "Epoch 93: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0558 - val_accuracy: 0.9939 - val_loss: 0.0658 - learning_rate: 1.2500e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0553\n",
      "Epoch 94: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0551 - val_accuracy: 0.9925 - val_loss: 0.0699 - learning_rate: 1.2500e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0569\n",
      "Epoch 95: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0563 - val_accuracy: 0.9925 - val_loss: 0.0720 - learning_rate: 1.2500e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0614\n",
      "Epoch 96: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0608 - val_accuracy: 0.9932 - val_loss: 0.0697 - learning_rate: 1.2500e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0550\n",
      "Epoch 97: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0589 - val_accuracy: 0.9918 - val_loss: 0.0718 - learning_rate: 1.2500e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0616\n",
      "Epoch 98: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0574 - val_accuracy: 0.9952 - val_loss: 0.0655 - learning_rate: 1.2500e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0577\n",
      "Epoch 99: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0560 - val_accuracy: 0.9939 - val_loss: 0.0651 - learning_rate: 1.2500e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0547\n",
      "Epoch 100: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0551 - val_accuracy: 0.9939 - val_loss: 0.0637 - learning_rate: 1.2500e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0537\n",
      "Epoch 101: val_accuracy did not improve from 0.99523\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0518 - val_accuracy: 0.9946 - val_loss: 0.0677 - learning_rate: 1.2500e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0552\n",
      "Epoch 102: val_accuracy improved from 0.99523 to 0.99728, saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\n",
      "Epoch 102: finished saving model to ../models/20260115_151143/swipe_gesture_classifier.keras\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0533 - val_accuracy: 0.9973 - val_loss: 0.0574 - learning_rate: 1.2500e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0604\n",
      "Epoch 103: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0552 - val_accuracy: 0.9946 - val_loss: 0.0644 - learning_rate: 1.2500e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0532\n",
      "Epoch 104: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0541 - val_accuracy: 0.9939 - val_loss: 0.0622 - learning_rate: 1.2500e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0565\n",
      "Epoch 105: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0574 - val_accuracy: 0.9946 - val_loss: 0.0642 - learning_rate: 1.2500e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0572\n",
      "Epoch 106: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0524 - val_accuracy: 0.9939 - val_loss: 0.0661 - learning_rate: 1.2500e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0553\n",
      "Epoch 107: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0533 - val_accuracy: 0.9932 - val_loss: 0.0633 - learning_rate: 1.2500e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0509\n",
      "Epoch 108: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0519 - val_accuracy: 0.9952 - val_loss: 0.0551 - learning_rate: 1.2500e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0484\n",
      "Epoch 109: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0500 - val_accuracy: 0.9952 - val_loss: 0.0603 - learning_rate: 1.2500e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0579\n",
      "Epoch 110: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0541 - val_accuracy: 0.9939 - val_loss: 0.0682 - learning_rate: 1.2500e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0521\n",
      "Epoch 111: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0513 - val_accuracy: 0.9952 - val_loss: 0.0605 - learning_rate: 1.2500e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0532\n",
      "Epoch 112: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0512 - val_accuracy: 0.9932 - val_loss: 0.0647 - learning_rate: 1.2500e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0548\n",
      "Epoch 113: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0527 - val_accuracy: 0.9918 - val_loss: 0.0648 - learning_rate: 1.2500e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0529\n",
      "Epoch 114: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0504 - val_accuracy: 0.9925 - val_loss: 0.0699 - learning_rate: 1.2500e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0520\n",
      "Epoch 115: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0506 - val_accuracy: 0.9946 - val_loss: 0.0556 - learning_rate: 1.2500e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0513\n",
      "Epoch 116: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0525 - val_accuracy: 0.9946 - val_loss: 0.0582 - learning_rate: 1.2500e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0539\n",
      "Epoch 117: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0519 - val_accuracy: 0.9946 - val_loss: 0.0594 - learning_rate: 1.2500e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0530\n",
      "Epoch 118: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0501 - val_accuracy: 0.9939 - val_loss: 0.0608 - learning_rate: 1.2500e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0447\n",
      "Epoch 119: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0455 - val_accuracy: 0.9952 - val_loss: 0.0600 - learning_rate: 6.2500e-05\n",
      "Epoch 120/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0467\n",
      "Epoch 120: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0450 - val_accuracy: 0.9952 - val_loss: 0.0626 - learning_rate: 6.2500e-05\n",
      "Epoch 121/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0454\n",
      "Epoch 121: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0446 - val_accuracy: 0.9959 - val_loss: 0.0565 - learning_rate: 6.2500e-05\n",
      "Epoch 122/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0431\n",
      "Epoch 122: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0418 - val_accuracy: 0.9966 - val_loss: 0.0580 - learning_rate: 6.2500e-05\n",
      "Epoch 123/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0457\n",
      "Epoch 123: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0419 - val_accuracy: 0.9952 - val_loss: 0.0549 - learning_rate: 6.2500e-05\n",
      "Epoch 124/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0453\n",
      "Epoch 124: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0472 - val_accuracy: 0.9952 - val_loss: 0.0543 - learning_rate: 6.2500e-05\n",
      "Epoch 125/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0469\n",
      "Epoch 125: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0459 - val_accuracy: 0.9959 - val_loss: 0.0522 - learning_rate: 6.2500e-05\n",
      "Epoch 126/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0420\n",
      "Epoch 126: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0415 - val_accuracy: 0.9959 - val_loss: 0.0548 - learning_rate: 6.2500e-05\n",
      "Epoch 127/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0416\n",
      "Epoch 127: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0430 - val_accuracy: 0.9939 - val_loss: 0.0603 - learning_rate: 6.2500e-05\n",
      "Epoch 128/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0437\n",
      "Epoch 128: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0433 - val_accuracy: 0.9952 - val_loss: 0.0553 - learning_rate: 6.2500e-05\n",
      "Epoch 129/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0420\n",
      "Epoch 129: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0414 - val_accuracy: 0.9959 - val_loss: 0.0524 - learning_rate: 6.2500e-05\n",
      "Epoch 130/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0413\n",
      "Epoch 130: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0412 - val_accuracy: 0.9952 - val_loss: 0.0580 - learning_rate: 6.2500e-05\n",
      "Epoch 131/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0434\n",
      "Epoch 131: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0425 - val_accuracy: 0.9959 - val_loss: 0.0539 - learning_rate: 6.2500e-05\n",
      "Epoch 132/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0420\n",
      "Epoch 132: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0422 - val_accuracy: 0.9959 - val_loss: 0.0564 - learning_rate: 6.2500e-05\n",
      "Epoch 133/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0409\n",
      "Epoch 133: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0394 - val_accuracy: 0.9959 - val_loss: 0.0538 - learning_rate: 6.2500e-05\n",
      "Epoch 134/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0379\n",
      "Epoch 134: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0395 - val_accuracy: 0.9946 - val_loss: 0.0537 - learning_rate: 6.2500e-05\n",
      "Epoch 135/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0423\n",
      "Epoch 135: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0401 - val_accuracy: 0.9932 - val_loss: 0.0574 - learning_rate: 6.2500e-05\n",
      "Epoch 136/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0459\n",
      "Epoch 136: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0430 - val_accuracy: 0.9946 - val_loss: 0.0530 - learning_rate: 3.1250e-05\n",
      "Epoch 137/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0372\n",
      "Epoch 137: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0399 - val_accuracy: 0.9939 - val_loss: 0.0571 - learning_rate: 3.1250e-05\n",
      "Epoch 138/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0394\n",
      "Epoch 138: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0377 - val_accuracy: 0.9952 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
      "Epoch 139/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0396\n",
      "Epoch 139: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0378 - val_accuracy: 0.9946 - val_loss: 0.0530 - learning_rate: 3.1250e-05\n",
      "Epoch 140/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0375\n",
      "Epoch 140: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0380 - val_accuracy: 0.9946 - val_loss: 0.0520 - learning_rate: 3.1250e-05\n",
      "Epoch 141/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0369\n",
      "Epoch 141: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0369 - val_accuracy: 0.9959 - val_loss: 0.0514 - learning_rate: 3.1250e-05\n",
      "Epoch 142/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0379\n",
      "Epoch 142: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0359 - val_accuracy: 0.9952 - val_loss: 0.0519 - learning_rate: 3.1250e-05\n",
      "Epoch 143/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0377\n",
      "Epoch 143: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0372 - val_accuracy: 0.9952 - val_loss: 0.0524 - learning_rate: 3.1250e-05\n",
      "Epoch 144/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0383\n",
      "Epoch 144: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0378 - val_accuracy: 0.9946 - val_loss: 0.0533 - learning_rate: 3.1250e-05\n",
      "Epoch 145/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0362\n",
      "Epoch 145: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0361 - val_accuracy: 0.9952 - val_loss: 0.0557 - learning_rate: 3.1250e-05\n",
      "Epoch 146/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0368\n",
      "Epoch 146: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0377 - val_accuracy: 0.9939 - val_loss: 0.0541 - learning_rate: 3.1250e-05\n",
      "Epoch 147/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0410\n",
      "Epoch 147: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0371 - val_accuracy: 0.9952 - val_loss: 0.0519 - learning_rate: 3.1250e-05\n",
      "Epoch 148/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0387\n",
      "Epoch 148: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0363 - val_accuracy: 0.9952 - val_loss: 0.0522 - learning_rate: 3.1250e-05\n",
      "Epoch 149/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0351\n",
      "Epoch 149: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0350 - val_accuracy: 0.9959 - val_loss: 0.0523 - learning_rate: 3.1250e-05\n",
      "Epoch 150/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0360\n",
      "Epoch 150: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0361 - val_accuracy: 0.9959 - val_loss: 0.0484 - learning_rate: 3.1250e-05\n",
      "Epoch 151/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0338\n",
      "Epoch 151: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0350 - val_accuracy: 0.9959 - val_loss: 0.0486 - learning_rate: 3.1250e-05\n",
      "Epoch 152/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0362\n",
      "Epoch 152: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0364 - val_accuracy: 0.9966 - val_loss: 0.0510 - learning_rate: 3.1250e-05\n",
      "Epoch 153/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0348\n",
      "Epoch 153: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0363 - val_accuracy: 0.9952 - val_loss: 0.0539 - learning_rate: 3.1250e-05\n",
      "Epoch 154/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0359\n",
      "Epoch 154: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0346 - val_accuracy: 0.9959 - val_loss: 0.0538 - learning_rate: 3.1250e-05\n",
      "Epoch 155/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0361\n",
      "Epoch 155: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0362 - val_accuracy: 0.9952 - val_loss: 0.0535 - learning_rate: 3.1250e-05\n",
      "Epoch 156/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0394\n",
      "Epoch 156: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0379 - val_accuracy: 0.9952 - val_loss: 0.0519 - learning_rate: 3.1250e-05\n",
      "Epoch 157/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0353\n",
      "Epoch 157: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0351 - val_accuracy: 0.9952 - val_loss: 0.0494 - learning_rate: 3.1250e-05\n",
      "Epoch 158/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0360\n",
      "Epoch 158: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0361 - val_accuracy: 0.9952 - val_loss: 0.0502 - learning_rate: 3.1250e-05\n",
      "Epoch 159/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0343\n",
      "Epoch 159: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0337 - val_accuracy: 0.9959 - val_loss: 0.0481 - learning_rate: 3.1250e-05\n",
      "Epoch 160/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0348\n",
      "Epoch 160: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0349 - val_accuracy: 0.9946 - val_loss: 0.0522 - learning_rate: 3.1250e-05\n",
      "Epoch 161/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0328\n",
      "Epoch 161: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0340 - val_accuracy: 0.9959 - val_loss: 0.0498 - learning_rate: 3.1250e-05\n",
      "Epoch 162/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0337\n",
      "Epoch 162: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0345 - val_accuracy: 0.9966 - val_loss: 0.0457 - learning_rate: 3.1250e-05\n",
      "Epoch 163/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0367\n",
      "Epoch 163: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0359 - val_accuracy: 0.9959 - val_loss: 0.0474 - learning_rate: 3.1250e-05\n",
      "Epoch 164/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0383\n",
      "Epoch 164: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0367 - val_accuracy: 0.9959 - val_loss: 0.0530 - learning_rate: 3.1250e-05\n",
      "Epoch 165/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0345\n",
      "Epoch 165: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0350 - val_accuracy: 0.9952 - val_loss: 0.0512 - learning_rate: 3.1250e-05\n",
      "Epoch 166/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0339\n",
      "Epoch 166: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0346 - val_accuracy: 0.9959 - val_loss: 0.0519 - learning_rate: 3.1250e-05\n",
      "Epoch 167/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0389\n",
      "Epoch 167: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0358 - val_accuracy: 0.9959 - val_loss: 0.0490 - learning_rate: 3.1250e-05\n",
      "Epoch 168/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0324\n",
      "Epoch 168: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0325 - val_accuracy: 0.9966 - val_loss: 0.0470 - learning_rate: 3.1250e-05\n",
      "Epoch 169/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0324\n",
      "Epoch 169: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0321 - val_accuracy: 0.9952 - val_loss: 0.0485 - learning_rate: 3.1250e-05\n",
      "Epoch 170/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0358\n",
      "Epoch 170: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0346 - val_accuracy: 0.9959 - val_loss: 0.0480 - learning_rate: 3.1250e-05\n",
      "Epoch 171/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0309\n",
      "Epoch 171: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0310 - val_accuracy: 0.9952 - val_loss: 0.0491 - learning_rate: 3.1250e-05\n",
      "Epoch 172/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0318\n",
      "Epoch 172: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 172: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0313 - val_accuracy: 0.9952 - val_loss: 0.0525 - learning_rate: 3.1250e-05\n",
      "Epoch 173/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0313\n",
      "Epoch 173: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0320 - val_accuracy: 0.9952 - val_loss: 0.0534 - learning_rate: 1.5625e-05\n",
      "Epoch 174/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0313\n",
      "Epoch 174: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0316 - val_accuracy: 0.9959 - val_loss: 0.0490 - learning_rate: 1.5625e-05\n",
      "Epoch 175/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0311\n",
      "Epoch 175: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0322 - val_accuracy: 0.9959 - val_loss: 0.0486 - learning_rate: 1.5625e-05\n",
      "Epoch 176/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0335\n",
      "Epoch 176: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0319 - val_accuracy: 0.9959 - val_loss: 0.0492 - learning_rate: 1.5625e-05\n",
      "Epoch 177/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0308\n",
      "Epoch 177: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0314 - val_accuracy: 0.9959 - val_loss: 0.0492 - learning_rate: 1.5625e-05\n",
      "Epoch 178/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0319\n",
      "Epoch 178: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0321 - val_accuracy: 0.9952 - val_loss: 0.0509 - learning_rate: 1.5625e-05\n",
      "Epoch 179/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0312\n",
      "Epoch 179: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0313 - val_accuracy: 0.9946 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
      "Epoch 180/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0317\n",
      "Epoch 180: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0306 - val_accuracy: 0.9946 - val_loss: 0.0522 - learning_rate: 1.5625e-05\n",
      "Epoch 181/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0305\n",
      "Epoch 181: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0310 - val_accuracy: 0.9952 - val_loss: 0.0492 - learning_rate: 1.5625e-05\n",
      "Epoch 182/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0302\n",
      "Epoch 182: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0309 - val_accuracy: 0.9959 - val_loss: 0.0453 - learning_rate: 1.5625e-05\n",
      "Epoch 183/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0305\n",
      "Epoch 183: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0306 - val_accuracy: 0.9952 - val_loss: 0.0472 - learning_rate: 1.5625e-05\n",
      "Epoch 184/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0305\n",
      "Epoch 184: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0305 - val_accuracy: 0.9959 - val_loss: 0.0456 - learning_rate: 1.5625e-05\n",
      "Epoch 185/300\n",
      "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0299\n",
      "Epoch 185: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0306 - val_accuracy: 0.9959 - val_loss: 0.0452 - learning_rate: 1.5625e-05\n",
      "Epoch 186/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0297\n",
      "Epoch 186: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0298 - val_accuracy: 0.9959 - val_loss: 0.0455 - learning_rate: 1.5625e-05\n",
      "Epoch 187/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0303\n",
      "Epoch 187: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0303 - val_accuracy: 0.9952 - val_loss: 0.0470 - learning_rate: 1.5625e-05\n",
      "Epoch 188/300\n",
      "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0296\n",
      "Epoch 188: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0297 - val_accuracy: 0.9959 - val_loss: 0.0485 - learning_rate: 1.5625e-05\n",
      "Epoch 189/300\n",
      "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0298\n",
      "Epoch 189: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0302 - val_accuracy: 0.9959 - val_loss: 0.0466 - learning_rate: 1.5625e-05\n",
      "Epoch 190/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0295\n",
      "Epoch 190: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0290 - val_accuracy: 0.9959 - val_loss: 0.0470 - learning_rate: 1.5625e-05\n",
      "Epoch 191/300\n",
      "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0318\n",
      "Epoch 191: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0305 - val_accuracy: 0.9959 - val_loss: 0.0461 - learning_rate: 1.5625e-05\n",
      "Epoch 192/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0302\n",
      "Epoch 192: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0302 - val_accuracy: 0.9959 - val_loss: 0.0455 - learning_rate: 1.5625e-05\n",
      "Epoch 193/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0314\n",
      "Epoch 193: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0299 - val_accuracy: 0.9959 - val_loss: 0.0465 - learning_rate: 1.5625e-05\n",
      "Epoch 194/300\n",
      "\u001b[1m361/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0296\n",
      "Epoch 194: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0296 - val_accuracy: 0.9959 - val_loss: 0.0495 - learning_rate: 1.5625e-05\n",
      "Epoch 195/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0295\n",
      "Epoch 195: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0299 - val_accuracy: 0.9952 - val_loss: 0.0486 - learning_rate: 1.5625e-05\n",
      "Epoch 196/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0291\n",
      "Epoch 196: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0290 - val_accuracy: 0.9959 - val_loss: 0.0477 - learning_rate: 7.8125e-06\n",
      "Epoch 197/300\n",
      "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0312\n",
      "Epoch 197: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0298 - val_accuracy: 0.9952 - val_loss: 0.0477 - learning_rate: 7.8125e-06\n",
      "Epoch 198/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0297\n",
      "Epoch 198: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0307 - val_accuracy: 0.9959 - val_loss: 0.0468 - learning_rate: 7.8125e-06\n",
      "Epoch 199/300\n",
      "\u001b[1m353/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0335\n",
      "Epoch 199: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0323 - val_accuracy: 0.9952 - val_loss: 0.0486 - learning_rate: 7.8125e-06\n",
      "Epoch 200/300\n",
      "\u001b[1m366/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0293\n",
      "Epoch 200: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0286 - val_accuracy: 0.9952 - val_loss: 0.0490 - learning_rate: 7.8125e-06\n",
      "Epoch 201/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0293\n",
      "Epoch 201: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0302 - val_accuracy: 0.9959 - val_loss: 0.0477 - learning_rate: 7.8125e-06\n",
      "Epoch 202/300\n",
      "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0287\n",
      "Epoch 202: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0287 - val_accuracy: 0.9952 - val_loss: 0.0482 - learning_rate: 7.8125e-06\n",
      "Epoch 203/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0278\n",
      "Epoch 203: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0282 - val_accuracy: 0.9952 - val_loss: 0.0481 - learning_rate: 7.8125e-06\n",
      "Epoch 204/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0297\n",
      "Epoch 204: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0297 - val_accuracy: 0.9952 - val_loss: 0.0474 - learning_rate: 7.8125e-06\n",
      "Epoch 205/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0296\n",
      "Epoch 205: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0285 - val_accuracy: 0.9952 - val_loss: 0.0477 - learning_rate: 7.8125e-06\n",
      "Epoch 206/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0284\n",
      "Epoch 206: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0290 - val_accuracy: 0.9952 - val_loss: 0.0478 - learning_rate: 3.9063e-06\n",
      "Epoch 207/300\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0282\n",
      "Epoch 207: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.9952 - val_loss: 0.0480 - learning_rate: 3.9063e-06\n",
      "Epoch 208/300\n",
      "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0286\n",
      "Epoch 208: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0289 - val_accuracy: 0.9952 - val_loss: 0.0478 - learning_rate: 3.9063e-06\n",
      "Epoch 209/300\n",
      "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0299\n",
      "Epoch 209: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0298 - val_accuracy: 0.9952 - val_loss: 0.0471 - learning_rate: 3.9063e-06\n",
      "Epoch 210/300\n",
      "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0298\n",
      "Epoch 210: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0293 - val_accuracy: 0.9952 - val_loss: 0.0475 - learning_rate: 3.9063e-06\n",
      "Epoch 211/300\n",
      "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0323\n",
      "Epoch 211: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0303 - val_accuracy: 0.9952 - val_loss: 0.0471 - learning_rate: 3.9063e-06\n",
      "Epoch 212/300\n",
      "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0281\n",
      "Epoch 212: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0288 - val_accuracy: 0.9952 - val_loss: 0.0473 - learning_rate: 3.9063e-06\n",
      "Epoch 213/300\n",
      "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0296\n",
      "Epoch 213: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0299 - val_accuracy: 0.9952 - val_loss: 0.0474 - learning_rate: 3.9063e-06\n",
      "Epoch 214/300\n",
      "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0290\n",
      "Epoch 214: val_accuracy did not improve from 0.99728\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0293 - val_accuracy: 0.9952 - val_loss: 0.0479 - learning_rate: 3.9063e-06\n",
      "Epoch 215/300\n",
      "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0294\n",
      "Epoch 215: val_accuracy did not improve from 0.99728\n",
      "\n",
      "Epoch 215: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0286 - val_accuracy: 0.9952 - val_loss: 0.0477 - learning_rate: 3.9063e-06\n",
      "Epoch 215: early stopping\n",
      "Restoring model weights from the end of the best epoch: 185.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Train')\n",
    "ax1.plot(history.history['val_loss'], label='Val')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], label='Val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-gesture       1.00      1.00      1.00       512\n",
      "  Swipe Left       1.00      0.99      1.00       586\n",
      " Swipe Right       0.99      0.99      0.99       371\n",
      "\n",
      "    accuracy                           1.00      1469\n",
      "   macro avg       1.00      1.00      1.00      1469\n",
      "weighted avg       1.00      1.00      1.00      1469\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[512   0   0]\n",
      " [  1 583   2]\n",
      " [  1   2 368]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-gesture', 'Swipe Left', 'Swipe Right']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmp2z720v2y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmp2z720v2y/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmp2z720v2y'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 16, 16), dtype=tf.float32, name='input_layer_10')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  14650899536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650896848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650897616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650898768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650898192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650900112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650900304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650892816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650899344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14650898000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665914128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665912400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665912016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665913936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665916240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665914704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665913360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665913168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665911248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665912592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665914896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665913552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665911632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690179856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690193872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690184080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690180048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690195408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690186768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13411554832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690194448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5690183696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13665915280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13411555600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14725699088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14725700624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite model saved to: ../models/20260115_151143/swipe_gesture_classifier.tflite\n",
      "Model size: 117.9 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1768464987.667089 18098542 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1768464987.667297 18098542 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Convert to TFLite (standard ops only - fully compatible)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save\n",
    "with open(TFLITE_SAVE_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {TFLITE_SAVE_PATH}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "✅ TensorFlow.js model saved to: ../models/20260115_151143/swipe_gesture_tfjs\n",
      "✅ Removed regularizers (only needed for training)\n",
      "✅ Fixed Keras 3 keys for TFJS compatibility\n",
      "  - model.json (14.3 KB)\n",
      "  - group1-shard1of1.bin (404.2 KB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(TFJS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Create a new model without regularizers (regularizers only affect training, not inference)\n",
    "model_config = model.get_config()\n",
    "\n",
    "# Remove regularizers from all layers\n",
    "for layer_config in model_config['layers']:\n",
    "    if 'kernel_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['kernel_regularizer'] = None\n",
    "    if 'bias_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['bias_regularizer'] = None\n",
    "    if 'activity_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['activity_regularizer'] = None\n",
    "\n",
    "# Reconstruct model without regularizers\n",
    "model_no_reg = tf.keras.Sequential.from_config(model_config)\n",
    "\n",
    "# Copy the trained weights\n",
    "model_no_reg.set_weights(model.get_weights())\n",
    "\n",
    "# Convert to TensorFlow.js\n",
    "tfjs.converters.save_keras_model(model_no_reg, TFJS_SAVE_DIR)\n",
    "\n",
    "# Fix Keras 3 to TFJS compatibility - replace keys in model.json\n",
    "model_json_path = os.path.join(TFJS_SAVE_DIR, 'model.json')\n",
    "with open(model_json_path, 'r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "# Replace Keras 3 keys with TFJS-compatible keys\n",
    "model_json_str = json.dumps(model_json)\n",
    "model_json_str = model_json_str.replace('\"batch_shape\"', '\"batchInputShape\"')\n",
    "model_json_str = model_json_str.replace('\"build_input_shape\"', '\"buildInputShape\"')\n",
    "model_json = json.loads(model_json_str)\n",
    "\n",
    "# Save the fixed model.json\n",
    "with open(model_json_path, 'w') as f:\n",
    "    json.dump(model_json, f)\n",
    "\n",
    "print(f\"✅ TensorFlow.js model saved to: {TFJS_SAVE_DIR}\")\n",
    "print(f\"✅ Removed regularizers (only needed for training)\")\n",
    "print(f\"✅ Fixed Keras 3 keys for TFJS compatibility\")\n",
    "\n",
    "# List output files\n",
    "for f in os.listdir(TFJS_SAVE_DIR):\n",
    "    filepath = os.path.join(TFJS_SAVE_DIR, f)\n",
    "    size = os.path.getsize(filepath) / 1024\n",
    "    print(f\"  - {f} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [ 1 16 16]\n",
      "Output shape: [1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikaizm/Documents/PROGRAMMING/ml-ai/hand-gesture-recognition-mediapipe/.venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_SAVE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1\n",
      "Actual: 1\n",
      "Probabilities: [2.4876254e-06 9.9999750e-01 3.7148151e-09]\n"
     ]
    }
   ],
   "source": [
    "# Test on a sample\n",
    "test_sample = X_test[0:1]\n",
    "interpreter.set_tensor(input_details[0]['index'], test_sample)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"Predicted: {output.argmax()}\")\n",
    "print(f\"Actual: {y_test[0]}\")\n",
    "print(f\"Probabilities: {output[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
