{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swipe Gesture Classification with LSTM\n",
    "\n",
    "Train an LSTM model to classify swipe gestures:\n",
    "- 0: Non-gesture\n",
    "- 1: Swipe Left\n",
    "- 2: Swipe Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths - UPDATE THESE AFTER RE-COLLECTING DATA WITH NEW FEATURES\n",
    "DATASET_PATHS = [\n",
    "    'model/point_history_classifier/swipe_gesture_20260102_134712.csv',\n",
    "    'model/point_history_classifier/swipe_gesture_20260103_032002.csv',\n",
    "    'model/point_history_classifier/swipe_gesture_20260106_051821.csv',\n",
    "]\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Model paths\n",
    "MODEL_SAVE_PATH = 'model/point_history_classifier/swipe_gesture_classifier_{}.keras'.format(current_time)\n",
    "TFLITE_SAVE_PATH = 'model/point_history_classifier/swipe_gesture_classifier_{}.tflite'.format(current_time)\n",
    "\n",
    "# Model parameters\n",
    "NUM_CLASSES = 3  # Non-gesture, Swipe Left, Swipe Right\n",
    "TIME_STEPS = 16  # History window size\n",
    "FEATURES_PER_STEP = 16  # [x, y, dx, dy, angle, dtheta] + 5 fingertips × 2 coords\n",
    "\n",
    "# Feature indices for reference:\n",
    "# 0-1: palm_x, palm_y (normalized by scale)\n",
    "# 2-3: dx, dy (velocity)\n",
    "# 4-5: angle, dtheta (orientation)\n",
    "# 6-7: thumb tip (x, y relative to palm)\n",
    "# 8-9: index tip\n",
    "# 10-11: middle tip\n",
    "# 12-13: ring tip\n",
    "# 14-15: pinky tip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4230, 257)\n",
      "Expected: (samples, 257)\n",
      "\n",
      "Labels: (4230,)\n",
      "Features: (4230, 256)\n",
      "\n",
      "Class distribution:\n",
      "  Class 0: 2017 samples (47.7%)\n",
      "  Class 1: 1168 samples (27.6%)\n",
      "  Class 2: 1045 samples (24.7%)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "datasets = []\n",
    "for path in DATASET_PATHS:\n",
    "    data = np.atleast_2d(\n",
    "        np.loadtxt(path, delimiter=',', dtype='float32')\n",
    "    )\n",
    "    datasets.append(data)\n",
    "\n",
    "data = np.vstack(datasets)\n",
    "\n",
    "# Expected columns: 1 (label) + TIME_STEPS * FEATURES_PER_STEP\n",
    "expected_cols = 1 + TIME_STEPS * FEATURES_PER_STEP\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Expected: (samples, {expected_cols})\")\n",
    "\n",
    "if data.shape[1] != expected_cols:\n",
    "    print(f\"\\n⚠️  WARNING: Data has {data.shape[1]} columns, expected {expected_cols}\")\n",
    "    print(\"Make sure you collected data with the new 16-feature format!\")\n",
    "\n",
    "# Split into labels and features\n",
    "y = data[:, 0].astype(int)\n",
    "X = data[:, 1:]\n",
    "\n",
    "print(f\"\\nLabels: {y.shape}\")\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    count = np.sum(y == i)\n",
    "    print(f\"  Class {i}: {count} samples ({100*count/len(y):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X: (4230, 16, 16)\n",
      "\n",
      "Train: (3384, 16, 16), Test: (846, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Reshape for LSTM: (samples, time_steps, features)\n",
    "X_reshaped = X.reshape(-1, TIME_STEPS, FEATURES_PER_STEP)\n",
    "print(f\"Reshaped X: {X_reshaped.shape}\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "print(f\"\\nTrain: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Conv1D instead of LSTM for full TFLite compatibility\n",
    "# # Note: Using explicit input_shape in first layer instead of Input layer for TFJS compatibility\n",
    "# model = tf.keras.Sequential([\n",
    "#     # First Conv1D layer with input_shape (TFJS compatible)\n",
    "#     tf.keras.layers.Conv1D(32, kernel_size=3, padding='same', activation='relu',\n",
    "#                           input_shape=(TIME_STEPS, FEATURES_PER_STEP)),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "#     # Dense layers\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikaizm/Documents/PROGRAMMING/ml-ai/binarimaji-signage/hand-gesture-recognition-mediapipe/.venv/lib/python3.11/site-packages/keras/src/layers/normalization/batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,424</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │         \u001b[38;5;34m2,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,424\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m28,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │         \u001b[38;5;34m9,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,531</span> (228.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,531\u001b[0m (228.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,987</span> (226.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,987\u001b[0m (226.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> (2.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m544\u001b[0m (2.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimized Conv1D model for handling 16 features and 3 motion gestures\n",
    "# Reduced to ~90k parameters while maintaining temporal pattern learning capability\n",
    "# TFLite/TFJS compatible\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input normalization - using input_shape for TFJS compatibility\n",
    "    tf.keras.layers.BatchNormalization(input_shape=(TIME_STEPS, FEATURES_PER_STEP)),\n",
    "    \n",
    "    # First Conv1D block - captures short-term temporal patterns\n",
    "    tf.keras.layers.Conv1D(48, kernel_size=3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Second Conv1D block - captures mid-range motion dynamics\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=5, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Third Conv1D block - captures longer temporal patterns\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=7, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Fourth Conv1D block - refines high-level gesture patterns\n",
    "    tf.keras.layers.Conv1D(48, kernel_size=3, padding='same', activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    # Dense layers for classification - reduced size\n",
    "    tf.keras.layers.Dense(32, activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH, \n",
    "        save_best_only=True, \n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=30, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, \n",
    "        patience=10, \n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.9668\n",
      "Epoch 1: val_accuracy improved from None to 0.91135, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 1: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.7590 - val_accuracy: 0.9113 - val_loss: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.5453\n",
      "Epoch 2: val_accuracy improved from 0.91135 to 0.94444, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 2: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.5351 - val_accuracy: 0.9444 - val_loss: 0.3796 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.4634\n",
      "Epoch 3: val_accuracy improved from 0.94444 to 0.95154, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 3: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9226 - loss: 0.4612 - val_accuracy: 0.9515 - val_loss: 0.3515 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.4454\n",
      "Epoch 4: val_accuracy improved from 0.95154 to 0.96572, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 4: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.4418 - val_accuracy: 0.9657 - val_loss: 0.3295 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.4055\n",
      "Epoch 5: val_accuracy improved from 0.96572 to 0.96690, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 5: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.4093 - val_accuracy: 0.9669 - val_loss: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9490 - loss: 0.3687\n",
      "Epoch 6: val_accuracy did not improve from 0.96690\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9400 - loss: 0.3857 - val_accuracy: 0.9657 - val_loss: 0.2942 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.3737\n",
      "Epoch 7: val_accuracy did not improve from 0.96690\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.3817 - val_accuracy: 0.9669 - val_loss: 0.2866 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.3558\n",
      "Epoch 8: val_accuracy improved from 0.96690 to 0.96927, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 8: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.3604 - val_accuracy: 0.9693 - val_loss: 0.2778 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9506 - loss: 0.3549\n",
      "Epoch 9: val_accuracy improved from 0.96927 to 0.97281, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 9: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.3492 - val_accuracy: 0.9728 - val_loss: 0.2671 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9576 - loss: 0.3196\n",
      "Epoch 10: val_accuracy did not improve from 0.97281\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.3202 - val_accuracy: 0.9728 - val_loss: 0.2561 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.3115\n",
      "Epoch 11: val_accuracy improved from 0.97281 to 0.97991, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 11: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9504 - loss: 0.3182 - val_accuracy: 0.9799 - val_loss: 0.2402 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.2963\n",
      "Epoch 12: val_accuracy did not improve from 0.97991\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.3023 - val_accuracy: 0.9764 - val_loss: 0.2260 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.2958\n",
      "Epoch 13: val_accuracy did not improve from 0.97991\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.3006 - val_accuracy: 0.9704 - val_loss: 0.2314 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.2815\n",
      "Epoch 14: val_accuracy improved from 0.97991 to 0.98463, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 14: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.2889 - val_accuracy: 0.9846 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9644 - loss: 0.2522\n",
      "Epoch 15: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.2649 - val_accuracy: 0.9811 - val_loss: 0.2016 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.2640\n",
      "Epoch 16: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.2706 - val_accuracy: 0.9787 - val_loss: 0.2023 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.2570\n",
      "Epoch 17: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.2579 - val_accuracy: 0.9846 - val_loss: 0.1924 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.2310\n",
      "Epoch 18: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.2370 - val_accuracy: 0.9728 - val_loss: 0.2224 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.2377\n",
      "Epoch 19: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.2488 - val_accuracy: 0.9716 - val_loss: 0.2103 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.2210\n",
      "Epoch 20: val_accuracy did not improve from 0.98463\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.2220 - val_accuracy: 0.9811 - val_loss: 0.1829 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.2284\n",
      "Epoch 21: val_accuracy improved from 0.98463 to 0.98700, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 21: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.2307 - val_accuracy: 0.9870 - val_loss: 0.1664 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.2140\n",
      "Epoch 22: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.2168 - val_accuracy: 0.9799 - val_loss: 0.1818 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.1912\n",
      "Epoch 23: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.2064 - val_accuracy: 0.9740 - val_loss: 0.1788 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.2002\n",
      "Epoch 24: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1975 - val_accuracy: 0.9846 - val_loss: 0.1565 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.2016\n",
      "Epoch 25: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.2125 - val_accuracy: 0.9799 - val_loss: 0.1614 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.1856\n",
      "Epoch 26: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.1954 - val_accuracy: 0.9775 - val_loss: 0.1639 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.1824\n",
      "Epoch 27: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.1884 - val_accuracy: 0.9787 - val_loss: 0.1590 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.1712\n",
      "Epoch 28: val_accuracy did not improve from 0.98700\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.1912 - val_accuracy: 0.9787 - val_loss: 0.1737 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.1920\n",
      "Epoch 29: val_accuracy improved from 0.98700 to 0.98818, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 29: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1963 - val_accuracy: 0.9882 - val_loss: 0.1349 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.1714\n",
      "Epoch 30: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.1796 - val_accuracy: 0.9799 - val_loss: 0.1591 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.1918\n",
      "Epoch 31: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.1835 - val_accuracy: 0.9775 - val_loss: 0.1740 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.1612\n",
      "Epoch 32: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.1764 - val_accuracy: 0.9823 - val_loss: 0.1435 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.1690\n",
      "Epoch 33: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.1786 - val_accuracy: 0.9787 - val_loss: 0.1475 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.1722\n",
      "Epoch 34: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.1731 - val_accuracy: 0.9811 - val_loss: 0.1502 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.1625\n",
      "Epoch 35: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.1782 - val_accuracy: 0.9846 - val_loss: 0.1399 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.1860\n",
      "Epoch 36: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.1807 - val_accuracy: 0.9811 - val_loss: 0.1495 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.1681\n",
      "Epoch 37: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.1732 - val_accuracy: 0.9835 - val_loss: 0.1345 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.1466\n",
      "Epoch 38: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.1521 - val_accuracy: 0.9870 - val_loss: 0.1328 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.1524\n",
      "Epoch 39: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.1521 - val_accuracy: 0.9858 - val_loss: 0.1342 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1369\n",
      "Epoch 40: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.1583 - val_accuracy: 0.9775 - val_loss: 0.1474 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.1618\n",
      "Epoch 41: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.1547 - val_accuracy: 0.9882 - val_loss: 0.1240 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.1488\n",
      "Epoch 42: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.1553 - val_accuracy: 0.9870 - val_loss: 0.1287 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.1565\n",
      "Epoch 43: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.1537 - val_accuracy: 0.9823 - val_loss: 0.1399 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.1387\n",
      "Epoch 44: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.1460 - val_accuracy: 0.9858 - val_loss: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m 91/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.1293\n",
      "Epoch 45: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.1445 - val_accuracy: 0.9787 - val_loss: 0.1504 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.1435\n",
      "Epoch 46: val_accuracy did not improve from 0.98818\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.1448 - val_accuracy: 0.9858 - val_loss: 0.1333 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.1605\n",
      "Epoch 47: val_accuracy improved from 0.98818 to 0.98936, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 47: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.1505 - val_accuracy: 0.9894 - val_loss: 0.1233 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.1375\n",
      "Epoch 48: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1394 - val_accuracy: 0.9870 - val_loss: 0.1294 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.1340\n",
      "Epoch 49: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.1443 - val_accuracy: 0.9728 - val_loss: 0.1663 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.1443\n",
      "Epoch 50: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1466 - val_accuracy: 0.9870 - val_loss: 0.1324 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.1306\n",
      "Epoch 51: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9814 - loss: 0.1448 - val_accuracy: 0.9858 - val_loss: 0.1338 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.1415\n",
      "Epoch 52: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1461 - val_accuracy: 0.9894 - val_loss: 0.1191 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.1348\n",
      "Epoch 53: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1431 - val_accuracy: 0.9811 - val_loss: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.1337\n",
      "Epoch 54: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.1363 - val_accuracy: 0.9858 - val_loss: 0.1346 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.1302\n",
      "Epoch 55: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1305 - val_accuracy: 0.9835 - val_loss: 0.1274 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.1227\n",
      "Epoch 56: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.1284 - val_accuracy: 0.9846 - val_loss: 0.1365 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.1360\n",
      "Epoch 57: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1413 - val_accuracy: 0.9846 - val_loss: 0.1286 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1408\n",
      "Epoch 58: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.1341 - val_accuracy: 0.9858 - val_loss: 0.1163 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.1282\n",
      "Epoch 59: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.1245 - val_accuracy: 0.9882 - val_loss: 0.1173 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.1325\n",
      "Epoch 60: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.1442 - val_accuracy: 0.9764 - val_loss: 0.1476 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.1322\n",
      "Epoch 61: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1391 - val_accuracy: 0.9823 - val_loss: 0.1371 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.1205\n",
      "Epoch 62: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.1252 - val_accuracy: 0.9858 - val_loss: 0.1156 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.1208\n",
      "Epoch 63: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9861 - loss: 0.1211 - val_accuracy: 0.9894 - val_loss: 0.1097 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.1174\n",
      "Epoch 64: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.1256 - val_accuracy: 0.9846 - val_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.1245\n",
      "Epoch 65: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.1235 - val_accuracy: 0.9870 - val_loss: 0.1181 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.1236\n",
      "Epoch 66: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.1256 - val_accuracy: 0.9823 - val_loss: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.1340\n",
      "Epoch 67: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.1336 - val_accuracy: 0.9846 - val_loss: 0.1247 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.1332\n",
      "Epoch 68: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.1334 - val_accuracy: 0.9870 - val_loss: 0.1322 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1290\n",
      "Epoch 69: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.1357 - val_accuracy: 0.9894 - val_loss: 0.1157 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.1480\n",
      "Epoch 70: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1303 - val_accuracy: 0.9882 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.1219\n",
      "Epoch 71: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.1328 - val_accuracy: 0.9835 - val_loss: 0.1304 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.1398\n",
      "Epoch 72: val_accuracy did not improve from 0.98936\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.1259 - val_accuracy: 0.9858 - val_loss: 0.1250 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.1175\n",
      "Epoch 73: val_accuracy did not improve from 0.98936\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.1252 - val_accuracy: 0.9846 - val_loss: 0.1213 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.1126\n",
      "Epoch 74: val_accuracy improved from 0.98936 to 0.99054, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 74: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.1125 - val_accuracy: 0.9905 - val_loss: 0.1072 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.1070\n",
      "Epoch 75: val_accuracy did not improve from 0.99054\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0982 - val_accuracy: 0.9882 - val_loss: 0.1142 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.1008\n",
      "Epoch 76: val_accuracy did not improve from 0.99054\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.1048 - val_accuracy: 0.9894 - val_loss: 0.1061 - learning_rate: 5.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.1020\n",
      "Epoch 77: val_accuracy did not improve from 0.99054\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0962 - val_accuracy: 0.9894 - val_loss: 0.1071 - learning_rate: 5.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0884\n",
      "Epoch 78: val_accuracy did not improve from 0.99054\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0912 - val_accuracy: 0.9905 - val_loss: 0.1014 - learning_rate: 5.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0965\n",
      "Epoch 79: val_accuracy improved from 0.99054 to 0.99173, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 79: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0937 - val_accuracy: 0.9917 - val_loss: 0.0952 - learning_rate: 5.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0899\n",
      "Epoch 80: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0932 - val_accuracy: 0.9882 - val_loss: 0.1042 - learning_rate: 5.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0878\n",
      "Epoch 81: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0879 - val_accuracy: 0.9858 - val_loss: 0.1119 - learning_rate: 5.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0887\n",
      "Epoch 82: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0890 - val_accuracy: 0.9882 - val_loss: 0.1032 - learning_rate: 5.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0815\n",
      "Epoch 83: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0900 - val_accuracy: 0.9894 - val_loss: 0.1115 - learning_rate: 5.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0970\n",
      "Epoch 84: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0928 - val_accuracy: 0.9905 - val_loss: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0848\n",
      "Epoch 85: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0842 - val_accuracy: 0.9882 - val_loss: 0.0951 - learning_rate: 5.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0791\n",
      "Epoch 86: val_accuracy did not improve from 0.99173\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0848 - val_accuracy: 0.9882 - val_loss: 0.1063 - learning_rate: 5.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0952\n",
      "Epoch 87: val_accuracy improved from 0.99173 to 0.99409, saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\n",
      "Epoch 87: finished saving model to model/point_history_classifier/swipe_gesture_classifier_20260106_112628.keras\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0898 - val_accuracy: 0.9941 - val_loss: 0.0865 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0830\n",
      "Epoch 88: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0839 - val_accuracy: 0.9917 - val_loss: 0.0891 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0776\n",
      "Epoch 89: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0772 - val_accuracy: 0.9870 - val_loss: 0.1069 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0797\n",
      "Epoch 90: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0817 - val_accuracy: 0.9929 - val_loss: 0.0957 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0885\n",
      "Epoch 91: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0849 - val_accuracy: 0.9882 - val_loss: 0.1103 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0807\n",
      "Epoch 92: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0806 - val_accuracy: 0.9917 - val_loss: 0.0932 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0749\n",
      "Epoch 93: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0744 - val_accuracy: 0.9929 - val_loss: 0.0873 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0772\n",
      "Epoch 94: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0875 - val_accuracy: 0.9846 - val_loss: 0.1091 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0872\n",
      "Epoch 95: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0871 - val_accuracy: 0.9882 - val_loss: 0.1081 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0846\n",
      "Epoch 96: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0907 - val_accuracy: 0.9870 - val_loss: 0.1008 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0805\n",
      "Epoch 97: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0831 - val_accuracy: 0.9894 - val_loss: 0.1001 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0728\n",
      "Epoch 98: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0717 - val_accuracy: 0.9905 - val_loss: 0.0910 - learning_rate: 2.5000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0661\n",
      "Epoch 99: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0683 - val_accuracy: 0.9870 - val_loss: 0.1048 - learning_rate: 2.5000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0659\n",
      "Epoch 100: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0661 - val_accuracy: 0.9905 - val_loss: 0.0946 - learning_rate: 2.5000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0633\n",
      "Epoch 101: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0638 - val_accuracy: 0.9905 - val_loss: 0.0894 - learning_rate: 2.5000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0624\n",
      "Epoch 102: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0644 - val_accuracy: 0.9905 - val_loss: 0.0972 - learning_rate: 2.5000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0638\n",
      "Epoch 103: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0603 - val_accuracy: 0.9882 - val_loss: 0.0897 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0623\n",
      "Epoch 104: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0617 - val_accuracy: 0.9905 - val_loss: 0.0879 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0603\n",
      "Epoch 105: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0599 - val_accuracy: 0.9894 - val_loss: 0.0879 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0569\n",
      "Epoch 106: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0587 - val_accuracy: 0.9894 - val_loss: 0.0915 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0586\n",
      "Epoch 107: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0591 - val_accuracy: 0.9905 - val_loss: 0.0864 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0532\n",
      "Epoch 108: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0534 - val_accuracy: 0.9917 - val_loss: 0.0813 - learning_rate: 1.2500e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0540\n",
      "Epoch 109: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0535 - val_accuracy: 0.9917 - val_loss: 0.0821 - learning_rate: 1.2500e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0533\n",
      "Epoch 110: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0537 - val_accuracy: 0.9905 - val_loss: 0.0847 - learning_rate: 1.2500e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0537\n",
      "Epoch 111: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0531 - val_accuracy: 0.9894 - val_loss: 0.0849 - learning_rate: 1.2500e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0512\n",
      "Epoch 112: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0519 - val_accuracy: 0.9917 - val_loss: 0.0872 - learning_rate: 1.2500e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0497\n",
      "Epoch 113: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0505 - val_accuracy: 0.9917 - val_loss: 0.0864 - learning_rate: 1.2500e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0533\n",
      "Epoch 114: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0534 - val_accuracy: 0.9917 - val_loss: 0.0857 - learning_rate: 1.2500e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0504\n",
      "Epoch 115: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0516 - val_accuracy: 0.9917 - val_loss: 0.0793 - learning_rate: 1.2500e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0509\n",
      "Epoch 116: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0503 - val_accuracy: 0.9905 - val_loss: 0.0830 - learning_rate: 1.2500e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0506\n",
      "Epoch 117: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0522 - val_accuracy: 0.9905 - val_loss: 0.0833 - learning_rate: 1.2500e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0528\n",
      "Epoch 118: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0521 - val_accuracy: 0.9917 - val_loss: 0.0790 - learning_rate: 1.2500e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0508\n",
      "Epoch 119: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0493 - val_accuracy: 0.9917 - val_loss: 0.0748 - learning_rate: 1.2500e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0465\n",
      "Epoch 120: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0472 - val_accuracy: 0.9905 - val_loss: 0.0794 - learning_rate: 1.2500e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0505\n",
      "Epoch 121: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0534 - val_accuracy: 0.9917 - val_loss: 0.0886 - learning_rate: 1.2500e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m 90/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0573\n",
      "Epoch 122: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0502 - val_accuracy: 0.9917 - val_loss: 0.0792 - learning_rate: 1.2500e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0491\n",
      "Epoch 123: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0495 - val_accuracy: 0.9917 - val_loss: 0.0874 - learning_rate: 1.2500e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0486\n",
      "Epoch 124: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0520 - val_accuracy: 0.9894 - val_loss: 0.0903 - learning_rate: 1.2500e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0499\n",
      "Epoch 125: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0474 - val_accuracy: 0.9917 - val_loss: 0.0813 - learning_rate: 1.2500e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0491\n",
      "Epoch 126: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0489 - val_accuracy: 0.9905 - val_loss: 0.0831 - learning_rate: 1.2500e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0449\n",
      "Epoch 127: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0451 - val_accuracy: 0.9917 - val_loss: 0.0782 - learning_rate: 1.2500e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0438\n",
      "Epoch 128: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0447 - val_accuracy: 0.9917 - val_loss: 0.0782 - learning_rate: 1.2500e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0464\n",
      "Epoch 129: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0450 - val_accuracy: 0.9917 - val_loss: 0.0767 - learning_rate: 1.2500e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0467\n",
      "Epoch 130: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0443 - val_accuracy: 0.9905 - val_loss: 0.0791 - learning_rate: 6.2500e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0431\n",
      "Epoch 131: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0439 - val_accuracy: 0.9917 - val_loss: 0.0794 - learning_rate: 6.2500e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0422\n",
      "Epoch 132: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0422 - val_accuracy: 0.9917 - val_loss: 0.0786 - learning_rate: 6.2500e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0428\n",
      "Epoch 133: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0431 - val_accuracy: 0.9917 - val_loss: 0.0782 - learning_rate: 6.2500e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0439\n",
      "Epoch 134: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0428 - val_accuracy: 0.9917 - val_loss: 0.0806 - learning_rate: 6.2500e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0461\n",
      "Epoch 135: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0433 - val_accuracy: 0.9917 - val_loss: 0.0751 - learning_rate: 6.2500e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0424\n",
      "Epoch 136: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0426 - val_accuracy: 0.9917 - val_loss: 0.0784 - learning_rate: 6.2500e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0409\n",
      "Epoch 137: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0418 - val_accuracy: 0.9917 - val_loss: 0.0787 - learning_rate: 6.2500e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m 96/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0412\n",
      "Epoch 138: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0425 - val_accuracy: 0.9917 - val_loss: 0.0785 - learning_rate: 6.2500e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0417\n",
      "Epoch 139: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 139: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0421 - val_accuracy: 0.9929 - val_loss: 0.0791 - learning_rate: 6.2500e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0410\n",
      "Epoch 140: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0412 - val_accuracy: 0.9917 - val_loss: 0.0788 - learning_rate: 3.1250e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0433\n",
      "Epoch 141: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0420 - val_accuracy: 0.9917 - val_loss: 0.0778 - learning_rate: 3.1250e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0400\n",
      "Epoch 142: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0408 - val_accuracy: 0.9917 - val_loss: 0.0777 - learning_rate: 3.1250e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0406\n",
      "Epoch 143: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0409 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 3.1250e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0424\n",
      "Epoch 144: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0420 - val_accuracy: 0.9917 - val_loss: 0.0753 - learning_rate: 3.1250e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0415\n",
      "Epoch 145: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0423 - val_accuracy: 0.9917 - val_loss: 0.0751 - learning_rate: 3.1250e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0419\n",
      "Epoch 146: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0424 - val_accuracy: 0.9917 - val_loss: 0.0762 - learning_rate: 3.1250e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0396\n",
      "Epoch 147: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0396 - val_accuracy: 0.9917 - val_loss: 0.0763 - learning_rate: 3.1250e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0423\n",
      "Epoch 148: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0434 - val_accuracy: 0.9917 - val_loss: 0.0762 - learning_rate: 3.1250e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0393\n",
      "Epoch 149: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0395 - val_accuracy: 0.9917 - val_loss: 0.0746 - learning_rate: 3.1250e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0389\n",
      "Epoch 150: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0397 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 3.1250e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0417\n",
      "Epoch 151: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0422 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 3.1250e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0393\n",
      "Epoch 152: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0402 - val_accuracy: 0.9917 - val_loss: 0.0751 - learning_rate: 3.1250e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0397\n",
      "Epoch 153: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0394 - val_accuracy: 0.9917 - val_loss: 0.0763 - learning_rate: 3.1250e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0391\n",
      "Epoch 154: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0393 - val_accuracy: 0.9917 - val_loss: 0.0757 - learning_rate: 3.1250e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0394\n",
      "Epoch 155: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0407 - val_accuracy: 0.9917 - val_loss: 0.0765 - learning_rate: 3.1250e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0386\n",
      "Epoch 156: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0392 - val_accuracy: 0.9917 - val_loss: 0.0772 - learning_rate: 3.1250e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0389\n",
      "Epoch 157: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0393 - val_accuracy: 0.9917 - val_loss: 0.0769 - learning_rate: 3.1250e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m 91/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0387\n",
      "Epoch 158: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0387 - val_accuracy: 0.9917 - val_loss: 0.0772 - learning_rate: 3.1250e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0387\n",
      "Epoch 159: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0385 - val_accuracy: 0.9917 - val_loss: 0.0757 - learning_rate: 3.1250e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m 91/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0382\n",
      "Epoch 160: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 0.9917 - val_loss: 0.0753 - learning_rate: 1.5625e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0384\n",
      "Epoch 161: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0389 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 1.5625e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0410\n",
      "Epoch 162: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0392 - val_accuracy: 0.9917 - val_loss: 0.0760 - learning_rate: 1.5625e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0376\n",
      "Epoch 163: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.9917 - val_loss: 0.0757 - learning_rate: 1.5625e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0393\n",
      "Epoch 164: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0391 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 1.5625e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m 95/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0386\n",
      "Epoch 165: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0388 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 1.5625e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0394\n",
      "Epoch 166: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0384 - val_accuracy: 0.9917 - val_loss: 0.0769 - learning_rate: 1.5625e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m104/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0386\n",
      "Epoch 167: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0395 - val_accuracy: 0.9917 - val_loss: 0.0760 - learning_rate: 1.5625e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m 91/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0386\n",
      "Epoch 168: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0382 - val_accuracy: 0.9917 - val_loss: 0.0769 - learning_rate: 1.5625e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0396\n",
      "Epoch 169: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 169: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0384 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 1.5625e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0385\n",
      "Epoch 170: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0381 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 7.8125e-06\n",
      "Epoch 171/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0378\n",
      "Epoch 171: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0381 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 7.8125e-06\n",
      "Epoch 172/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0375\n",
      "Epoch 172: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0380 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 7.8125e-06\n",
      "Epoch 173/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0374\n",
      "Epoch 173: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 7.8125e-06\n",
      "Epoch 174/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0390\n",
      "Epoch 174: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0383 - val_accuracy: 0.9917 - val_loss: 0.0747 - learning_rate: 7.8125e-06\n",
      "Epoch 175/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0405\n",
      "Epoch 175: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0394 - val_accuracy: 0.9917 - val_loss: 0.0752 - learning_rate: 7.8125e-06\n",
      "Epoch 176/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0373\n",
      "Epoch 176: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0379 - val_accuracy: 0.9917 - val_loss: 0.0750 - learning_rate: 7.8125e-06\n",
      "Epoch 177/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0372\n",
      "Epoch 177: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0380 - val_accuracy: 0.9917 - val_loss: 0.0747 - learning_rate: 7.8125e-06\n",
      "Epoch 178/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0380\n",
      "Epoch 178: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0375 - val_accuracy: 0.9917 - val_loss: 0.0744 - learning_rate: 7.8125e-06\n",
      "Epoch 179/200\n",
      "\u001b[1m 93/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0408\n",
      "Epoch 179: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0397 - val_accuracy: 0.9917 - val_loss: 0.0744 - learning_rate: 7.8125e-06\n",
      "Epoch 180/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0376\n",
      "Epoch 180: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0374 - val_accuracy: 0.9917 - val_loss: 0.0747 - learning_rate: 7.8125e-06\n",
      "Epoch 181/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0487\n",
      "Epoch 181: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0400 - val_accuracy: 0.9917 - val_loss: 0.0753 - learning_rate: 7.8125e-06\n",
      "Epoch 182/200\n",
      "\u001b[1m100/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0381\n",
      "Epoch 182: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0375 - val_accuracy: 0.9917 - val_loss: 0.0756 - learning_rate: 7.8125e-06\n",
      "Epoch 183/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0388\n",
      "Epoch 183: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0384 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 7.8125e-06\n",
      "Epoch 184/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0376\n",
      "Epoch 184: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0378 - val_accuracy: 0.9917 - val_loss: 0.0762 - learning_rate: 7.8125e-06\n",
      "Epoch 185/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0426\n",
      "Epoch 185: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0385 - val_accuracy: 0.9917 - val_loss: 0.0759 - learning_rate: 7.8125e-06\n",
      "Epoch 186/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0428\n",
      "Epoch 186: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0397 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 7.8125e-06\n",
      "Epoch 187/200\n",
      "\u001b[1m 99/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0366\n",
      "Epoch 187: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0370 - val_accuracy: 0.9917 - val_loss: 0.0759 - learning_rate: 7.8125e-06\n",
      "Epoch 188/200\n",
      "\u001b[1m 94/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0361\n",
      "Epoch 188: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0367 - val_accuracy: 0.9917 - val_loss: 0.0754 - learning_rate: 7.8125e-06\n",
      "Epoch 189/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0385\n",
      "Epoch 189: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0404 - val_accuracy: 0.9917 - val_loss: 0.0759 - learning_rate: 3.9063e-06\n",
      "Epoch 190/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0390\n",
      "Epoch 190: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0372 - val_accuracy: 0.9917 - val_loss: 0.0756 - learning_rate: 3.9063e-06\n",
      "Epoch 191/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0381\n",
      "Epoch 191: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0376 - val_accuracy: 0.9917 - val_loss: 0.0756 - learning_rate: 3.9063e-06\n",
      "Epoch 192/200\n",
      "\u001b[1m 97/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0368\n",
      "Epoch 192: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0371 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 3.9063e-06\n",
      "Epoch 193/200\n",
      "\u001b[1m 98/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0372\n",
      "Epoch 193: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0373 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 3.9063e-06\n",
      "Epoch 194/200\n",
      "\u001b[1m 92/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0366\n",
      "Epoch 194: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 3.9063e-06\n",
      "Epoch 195/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0378\n",
      "Epoch 195: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0375 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 3.9063e-06\n",
      "Epoch 196/200\n",
      "\u001b[1m103/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0366\n",
      "Epoch 196: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0369 - val_accuracy: 0.9917 - val_loss: 0.0757 - learning_rate: 3.9063e-06\n",
      "Epoch 197/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0362\n",
      "Epoch 197: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0362 - val_accuracy: 0.9917 - val_loss: 0.0756 - learning_rate: 3.9063e-06\n",
      "Epoch 198/200\n",
      "\u001b[1m102/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0380\n",
      "Epoch 198: val_accuracy did not improve from 0.99409\n",
      "\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0373 - val_accuracy: 0.9917 - val_loss: 0.0755 - learning_rate: 3.9063e-06\n",
      "Epoch 199/200\n",
      "\u001b[1m101/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0395\n",
      "Epoch 199: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0390 - val_accuracy: 0.9917 - val_loss: 0.0757 - learning_rate: 1.9531e-06\n",
      "Epoch 200/200\n",
      "\u001b[1m105/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0400\n",
      "Epoch 200: val_accuracy did not improve from 0.99409\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0376 - val_accuracy: 0.9917 - val_loss: 0.0758 - learning_rate: 1.9531e-06\n",
      "Restoring model weights from the end of the best epoch: 179.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='Train')\n",
    "ax1.plot(history.history['val_loss'], label='Val')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], label='Val')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-gesture       1.00      1.00      1.00       403\n",
      "  Swipe Left       0.99      0.98      0.99       234\n",
      " Swipe Right       0.99      0.99      0.99       209\n",
      "\n",
      "    accuracy                           0.99       846\n",
      "   macro avg       0.99      0.99      0.99       846\n",
      "weighted avg       0.99      0.99      0.99       846\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[403   0   0]\n",
      " [  2 230   2]\n",
      " [  0   3 206]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-gesture', 'Swipe Left', 'Swipe Right']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmpbucnmpr7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmpbucnmpr7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/hb/b1p7kpgj4s759vkptsfqzxzw0000gn/T/tmpbucnmpr7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 16, 16), dtype=tf.float32, name='input_layer_2')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  13444831888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444829008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444831504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444830352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444832080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444830928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444830160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444826128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444829392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444828624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444829584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444831312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444832464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444829776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444828432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444829968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444831120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4474658000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476412112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476412304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444828240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  13444832272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476412688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476412496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476411728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476413648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476413456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476412880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476413264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476411920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476411152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476414800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476414608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476411536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476416144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14476416720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite model saved to: model/point_history_classifier/swipe_gesture_classifier_20260106_112628.tflite\n",
      "Model size: 72.3 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1767673678.322439 3407614 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1767673678.322659 3407614 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Convert to TFLite (standard ops only - fully compatible)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save\n",
    "with open(TFLITE_SAVE_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {TFLITE_SAVE_PATH}\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "✅ TensorFlow.js model saved to: ../frontend/public/models/swipe_gesture_tfjs\n",
      "✅ Removed regularizers (only needed for training)\n",
      "✅ Fixed Keras 3 keys for TFJS compatibility\n",
      "  - model.json (14.3 KB)\n",
      "  - group1-shard1of1.bin (228.6 KB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "TFJS_SAVE_DIR = '../frontend/public/models/swipe_gesture_tfjs'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(TFJS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Create a new model without regularizers (regularizers only affect training, not inference)\n",
    "model_config = model.get_config()\n",
    "\n",
    "# Remove regularizers from all layers\n",
    "for layer_config in model_config['layers']:\n",
    "    if 'kernel_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['kernel_regularizer'] = None\n",
    "    if 'bias_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['bias_regularizer'] = None\n",
    "    if 'activity_regularizer' in layer_config['config']:\n",
    "        layer_config['config']['activity_regularizer'] = None\n",
    "\n",
    "# Reconstruct model without regularizers\n",
    "model_no_reg = tf.keras.Sequential.from_config(model_config)\n",
    "\n",
    "# Copy the trained weights\n",
    "model_no_reg.set_weights(model.get_weights())\n",
    "\n",
    "# Convert to TensorFlow.js\n",
    "tfjs.converters.save_keras_model(model_no_reg, TFJS_SAVE_DIR)\n",
    "\n",
    "# Fix Keras 3 to TFJS compatibility - replace keys in model.json\n",
    "model_json_path = os.path.join(TFJS_SAVE_DIR, 'model.json')\n",
    "with open(model_json_path, 'r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "# Replace Keras 3 keys with TFJS-compatible keys\n",
    "model_json_str = json.dumps(model_json)\n",
    "model_json_str = model_json_str.replace('\"batch_shape\"', '\"batchInputShape\"')\n",
    "model_json_str = model_json_str.replace('\"build_input_shape\"', '\"buildInputShape\"')\n",
    "model_json = json.loads(model_json_str)\n",
    "\n",
    "# Save the fixed model.json\n",
    "with open(model_json_path, 'w') as f:\n",
    "    json.dump(model_json, f)\n",
    "\n",
    "print(f\"✅ TensorFlow.js model saved to: {TFJS_SAVE_DIR}\")\n",
    "print(f\"✅ Removed regularizers (only needed for training)\")\n",
    "print(f\"✅ Fixed Keras 3 keys for TFJS compatibility\")\n",
    "\n",
    "# List output files\n",
    "for f in os.listdir(TFJS_SAVE_DIR):\n",
    "    filepath = os.path.join(TFJS_SAVE_DIR, f)\n",
    "    size = os.path.getsize(filepath) / 1024\n",
    "    print(f\"  - {f} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [ 1 16 16]\n",
      "Output shape: [1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikaizm/Documents/PROGRAMMING/ml-ai/binarimaji-signage/hand-gesture-recognition-mediapipe/.venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_SAVE_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 2\n",
      "Actual: 2\n",
      "Probabilities: [2.0855477e-06 4.8804035e-05 9.9994910e-01]\n"
     ]
    }
   ],
   "source": [
    "# Test on a sample\n",
    "test_sample = X_test[0:1]\n",
    "interpreter.set_tensor(input_details[0]['index'], test_sample)\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"Predicted: {output.argmax()}\")\n",
    "print(f\"Actual: {y_test[0]}\")\n",
    "print(f\"Probabilities: {output[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
